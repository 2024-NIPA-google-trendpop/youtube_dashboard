{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 3.12.4\n","# !pip install langchain-core==0.2.38 langsmith==0.1.117 langchain-community==0.2.16 langchain-experimental==0.0.65"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"Csco73vsbKS6"},"outputs":[],"source":["# 구글 생성형 AI 라이브러리를 가져옴\n","import google.generativeai as genai\n","\n","#에러가 발생할 경우 자동으로 재도전하도록 함\n","from google.api_core import retry\n","\n","# OS와 상호작용하기 위한 os 모듈을 임포트 (환경 변수나 파일 경로 관리 등에 사용)\n","import os\n","\n","# Langchain 라이브러리에서 프롬프트 템플릿을 가져옴\n","from langchain import PromptTemplate\n","\n","# 웹 페이지에서 문서를 로드하기 위한 WebBaseLoader를 임포트\n","from langchain.document_loaders import WebBaseLoader\n","\n","# Langchain에서 문자열 출력을 처리하기 위한 StrOutputParser 임포트\n","from langchain.schema import StrOutputParser\n","\n","# Langchain의 프롬프트 템플릿에서 문서 형식화를 위한 format_document 함수 임포트\n","from langchain.schema.prompt_template import format_document"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"ESrEMSXxccuh"},"outputs":[],"source":["# 'GOOGLE_API_KEY' 값을 가져와 API_KEY 변수에 저장\n","key_path = '/Users/jaesolshin/key/gemini_key.txt'\n","API_KEY = open(key_path, 'r', encoding='utf-8').read()\n","\n","# 구글 생성형 AI 라이브러리 설정을 API_KEY로 구성\n","genai.configure(api_key=API_KEY)"]},{"cell_type":"markdown","metadata":{"id":"TRGej4h8bfIW"},"source":["### 웹 사이트 데이터를 읽고 요약하기"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"gde1IvX5bYIr"},"outputs":[],"source":["loader = WebBaseLoader(\"https://blog.google/technology/ai/google-gemini-ai/#sundar-note\")\n","docs = loader.load()"]},{"cell_type":"markdown","metadata":{"id":"MTvNz9k6b7IL"},"source":["topK: 각 토큰 선택 단계에서 확률이 가장 높은 topK 토큰이 샘플링\n","\n","topP: 토큰은 확률이 가장 높은 것에서 가장 낮은 것부터 확률은 topP 값과 같습니다. 예를 들어 토큰 A, B, C의 확률은 0.3, 0.2, 0.1이고 topP 값이 0.5라면, 모델은 C를 후보에서 제외합니다. 기본 topP 값은 0.95입니다."]},{"cell_type":"code","execution_count":18,"metadata":{"id":"YYVhSa_Pbkde"},"outputs":[],"source":["from langchain_google_genai import ChatGoogleGenerativeAI\n","\n","# 모델 매개변수를 구성하려면 'generation_config' 매개변수를 사용합니다.\n","# 예: generation_config = {\"온도\": 0.7, \"topP\": 0.8, \"topK\": 40}\n","# 모델에 대한 사용자 지정 온도만 설정하려는 경우\n","# \"온도\" 매개 변수를 직접 입력합니다.\n","llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash-latest\")"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1728305542871,"user":{"displayName":"주식회사한시경","userId":"01036671795204052858"},"user_tz":-540},"id":"hkE_olHeckx2","outputId":"5f859426-7de8-4c08-f7bb-d408dbe84d69"},"outputs":[{"name":"stdout","output_type":"stream","text":["input_variables=['text'] template='다음에 대한 요약을 간결하게 작성합니다:\\n\\n\"{text}\"\\n\\n요약 내용:'\n"]}],"source":["# WebBaseLoader로부터 데이터 추출\n","doc_prompt = PromptTemplate.from_template(\"{page_content}\")\n","\n","# Gemini에 질의\n","llm_prompt_template = \"\"\"다음에 대한 요약을 간결하게 작성합니다:\n","\n","\"{text}\"\n","\n","요약 내용:\"\"\"\n","\n","# 'llm_prompt_template'로부터 프롬프트 템플릿 객체를 생성\n","llm_prompt = PromptTemplate.from_template(llm_prompt_template)\n","\n","# 생성된 프롬프트 템플릿을 출력\n","print(llm_prompt)"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"o-HhIrASczQ9"},"outputs":[],"source":["stuff_chain = (\n","    # 문서로부터 데이터를 추출하고 \"text\"라는 키를 추가.\n","    {\n","        \"text\": lambda docs: \"\\n\\n\".join(\n","            format_document(doc, doc_prompt) for doc in docs\n","        )\n","    }\n","    | llm_prompt         # Prompt for Gemini\n","    | llm                # Gemini API function\n","    | StrOutputParser()  # output parser\n",")"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":163},"executionInfo":{"elapsed":2390,"status":"ok","timestamp":1728305545256,"user":{"displayName":"주식회사한시경","userId":"01036671795204052858"},"user_tz":-540},"id":"izoofDbOdLDF","outputId":"56ee300f-37c8-4390-eac2-1020483ec792"},"outputs":[{"data":{"text/plain":["'Google은 Gemini라는 가장 강력하고 일반적인 AI 모델을 발표했습니다. Gemini는 텍스트, 코드, 오디오, 이미지, 비디오를 포함한 다양한 정보 유형을 이해하고 처리할 수 있는 다중 모드 모델입니다. Gemini는 학계의 벤치마크에서 최첨단 성능을 보였으며 특히 MMLU 및 MMMU 벤치마크에서 뛰어난 점수를 받았습니다. Gemini는 또한 코딩, 복잡한 추론 및 정보 추출에서도 뛰어난 성능을 보여줍니다.\\n\\nGemini는 세 가지 크기(Ultra, Pro, Nano)로 제공됩니다. Gemini Ultra는 가장 강력한 모델이며 Gemini Pro는 다양한 작업에 적합하고 Gemini Nano는 기기에서 사용하기에 가장 효율적인 모델입니다. Gemini는 현재 Google 제품(Bard, Pixel 8 Pro, Search)에서 사용 가능하며 개발자는 Google AI Studio 및 Google Cloud Vertex AI를 통해 Gemini API에 액세스할 수 있습니다.\\n\\nGoogle은 Gemini를 책임감 있게 개발하고 사용자의 안전과 프라이버시를 최우선으로 생각합니다. Google은 Gemini의 개발 과정에서 편향, 유해성, 사이버 공격, 설득력, 자율성을 포함한 잠재적 위험을 해결했습니다. Google은 또한 외부 전문가 및 파트너와 협력하여 Gemini의 안전성을 강화하고 있습니다.\\n\\nGoogle은 Gemini가 과학, 교육, 비즈니스와 같은 다양한 분야에서 혁신을 이끌어낼 잠재력이 있다고 믿습니다. Google은 Gemini를 지속적으로 개선하고 새로운 기능을 추가할 계획입니다. \\n'"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["stuff_chain.invoke(docs)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.4"}},"nbformat":4,"nbformat_minor":0}
